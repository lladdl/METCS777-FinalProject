{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c6f1b70-0975-40f3-ab8b-101fa9b919e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel interpreter: /opt/anaconda3/bin/python\n",
      "Requirement already satisfied: pip in /opt/anaconda3/lib/python3.12/site-packages (24.2)\n",
      "Collecting pip\n",
      "  Using cached pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (75.1.0)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: wheel in /opt/anaconda3/lib/python3.12/site-packages (0.44.0)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Using cached pip-25.3-py3-none-any.whl (1.8 MB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: wheel, setuptools, pip\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.44.0\n",
      "    Uninstalling wheel-0.44.0:\n",
      "      Successfully uninstalled wheel-0.44.0\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 75.1.0\n",
      "    Uninstalling setuptools-75.1.0:\n",
      "      Successfully uninstalled setuptools-75.1.0\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.2\n",
      "    Uninstalling pip-24.2:\n",
      "      Successfully uninstalled pip-24.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.5.1 requires sympy==1.13.1; python_version >= \"3.9\", but you have sympy 1.13.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed pip-25.3 setuptools-80.9.0 wheel-0.45.1\n",
      "Collecting geopandas\n",
      "  Downloading geopandas-1.1.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting folium\n",
      "  Using cached folium-0.20.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting branca\n",
      "  Using cached branca-0.8.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pyproj\n",
      "  Downloading pyproj-3.7.2-cp312-cp312-macosx_14_0_arm64.whl.metadata (31 kB)\n",
      "Collecting shapely\n",
      "  Downloading shapely-2.1.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting pyogrio\n",
      "  Downloading pyogrio-0.12.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.24 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (24.1)\n",
      "Requirement already satisfied: pandas>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from geopandas) (2.2.3)\n",
      "Requirement already satisfied: jinja2>=2.9 in /opt/anaconda3/lib/python3.12/site-packages (from folium) (3.1.4)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from folium) (2.32.3)\n",
      "Requirement already satisfied: xyzservices in /opt/anaconda3/lib/python3.12/site-packages (from folium) (2022.9.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from pyproj) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2>=2.9->folium) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=2.0.0->geopandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=2.0.0->geopandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=2.0.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->geopandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->folium) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->folium) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->folium) (2.2.3)\n",
      "Downloading geopandas-1.1.1-py3-none-any.whl (338 kB)\n",
      "Using cached folium-0.20.0-py2.py3-none-any.whl (113 kB)\n",
      "Using cached branca-0.8.2-py3-none-any.whl (26 kB)\n",
      "Downloading pyproj-3.7.2-cp312-cp312-macosx_14_0_arm64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.1.2-cp312-cp312-macosx_11_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyogrio-0.12.1-cp312-cp312-macosx_12_0_arm64.whl (23.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: shapely, pyproj, pyogrio, branca, geopandas, folium\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [folium]2m4/6\u001b[0m [geopandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed branca-0.8.2 folium-0.20.0 geopandas-1.1.1 pyogrio-0.12.1 pyproj-3.7.2 shapely-2.1.2\n",
      "Has geopandas? True\n"
     ]
    }
   ],
   "source": [
    "import sys, pkgutil, subprocess, json\n",
    "print(\"Kernel interpreter:\", sys.executable)\n",
    "\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\",\n",
    "                       \"pip\", \"setuptools\", \"wheel\"])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-U\",\n",
    "                       \"geopandas\", \"folium\", \"branca\", \"pyproj\", \"shapely\", \"pyogrio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f64037b4-3ce8-490a-bd0a-8ff37a334448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[saved combined metrics] /Users/reesemullen/maps_by_model_metric/combined_by_community_metrics.csv\n",
      "[saved map] /Users/reesemullen/maps_by_model_metric/Gradient_Boosted_Trees_FP_rate.html\n",
      "[saved map] /Users/reesemullen/maps_by_model_metric/Gradient_Boosted_Trees_FN_rate.html\n",
      "[saved map] /Users/reesemullen/maps_by_model_metric/Logistic_Regression_FP_rate.html\n",
      "[saved map] /Users/reesemullen/maps_by_model_metric/Logistic_Regression_FN_rate.html\n",
      "[saved map] /Users/reesemullen/maps_by_model_metric/Random_Forest_FP_rate.html\n",
      "[saved map] /Users/reesemullen/maps_by_model_metric/Random_Forest_FN_rate.html\n",
      "[saved map] /Users/reesemullen/maps_by_model_metric/Arrest_Rate_true.html\n"
     ]
    }
   ],
   "source": [
    "import os, json, math, webbrowser, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from branca.colormap import LinearColormap\n",
    "\n",
    "# inputs\n",
    "LR_CSV  = \"/Users/reesemullen/Downloads/lr_metrics_by_community_area.csv\"   # updated naming\n",
    "RF_CSV  = \"/Users/reesemullen/Downloads/rf_metrics_by_community_area.csv\"\n",
    "GBT_CSV = \"/Users/reesemullen/Downloads/xgb_metrics_by_community_area.csv\"\n",
    "\n",
    "MODEL_LABELS = {\n",
    "    LR_CSV:  \"Logistic_Regression\",\n",
    "    RF_CSV:  \"Random_Forest\",\n",
    "    GBT_CSV: \"Gradient_Boosted_Trees\",\n",
    "}\n",
    "\n",
    "# Chicago community areas shapefile\n",
    "COMMUNITY_SHP = \"/Users/reesemullen/Downloads/Boundaries - Community Areas_20251208/geo_export_0e4862d7-dcba-4d83-aafc-60ce367251d6.shp\"\n",
    "PER_MODEL_METRICS = [\"FP_rate\", \"FN_rate\"]\n",
    "SINGLE_METRIC = \"Arrest_Rate_true\"\n",
    "\n",
    "MIN_SUPPORT = 200\n",
    "OUT_DIR = \"maps_by_model_metric\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# normalization\n",
    "def _normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    def norm(c):\n",
    "        c = c.strip().lower()\n",
    "        c = re.sub(r\"[^0-9a-z]+\", \"_\", c)\n",
    "        c = re.sub(r\"_+\", \"_\", c).strip(\"_\")\n",
    "        return c\n",
    "    return df.rename(columns={c: norm(c) for c in df.columns})\n",
    "\n",
    "COL_ALIASES = {\n",
    "    \"community_area\": [\n",
    "        \"community_area\",\"community\",\"area\",\"area_id\",\"comm_area\",\n",
    "        \"area_num\",\"area_number\",\"area_numbe\",\"community_area_id\",\n",
    "        \"communityarea\",\"community_area_number\"\n",
    "    ],\n",
    "    \"fp_rate\": [\n",
    "        \"fp_rate\",\"false_positive_rate\",\"fp\",\"fpr\",\"fp_pct\",\"fp_percent\",\"fp_rate_mean\"\n",
    "    ],\n",
    "    \"fn_rate\": [\n",
    "        \"fn_rate\",\"false_negative_rate\",\"fn\",\"fnr\",\"fn_pct\",\"fn_percent\",\"fn_rate_mean\"\n",
    "    ],\n",
    "    \"n_obs\": [\n",
    "        \"n_obs\",\"n\",\"count\",\"support\",\"n_test\",\"nrows\",\"n_samples\",\"num_obs\"\n",
    "    ],\n",
    "    \"arrest_rate_true\": [\n",
    "        \"arrest_rate_true\", \"arrestrate_true\", \"arrest_rate_obs\",\n",
    "        \"arrest_rate_actual\", \"true_arrest_rate\", \"arrest_rate\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "def _resolve_col(df: pd.DataFrame, logical_name: str, required: bool=True):\n",
    "    for cand in COL_ALIASES[logical_name]:\n",
    "        if cand in df.columns:\n",
    "            return cand\n",
    "    if required:\n",
    "        raise ValueError(f\"Could not find a column for '{logical_name}'. \"\n",
    "                         f\"Available columns: {list(df.columns)[:20]}\")\n",
    "    return None\n",
    "\n",
    "def read_and_label(csv_path: str, label: str) -> pd.DataFrame:\n",
    "    df_raw = pd.read_csv(csv_path)\n",
    "    df = _normalize_columns(df_raw)\n",
    "\n",
    "    ca_col = _resolve_col(df, \"community_area\", required=True)\n",
    "    fp_col = _resolve_col(df, \"fp_rate\", required=False)\n",
    "    fn_col = _resolve_col(df, \"fn_rate\", required=False)\n",
    "    n_col  = _resolve_col(df, \"n_obs\",  required=False)\n",
    "    ar_true_col = _resolve_col(df, \"arrest_rate_true\", required=False)\n",
    "\n",
    "    out = pd.DataFrame()\n",
    "    out[\"community_area\"] = pd.to_numeric(df[ca_col], errors=\"coerce\").astype(\"Int64\")\n",
    "    if fp_col is not None:      out[\"FP_rate\"]          = pd.to_numeric(df[fp_col], errors=\"coerce\")\n",
    "    if fn_col is not None:      out[\"FN_rate\"]          = pd.to_numeric(df[fn_col], errors=\"coerce\")\n",
    "    if n_col  is not None:      out[\"n_obs\"]            = pd.to_numeric(df[n_col],  errors=\"coerce\")\n",
    "    if ar_true_col is not None: out[\"Arrest_Rate_true\"] = pd.to_numeric(df[ar_true_col], errors=\"coerce\")\n",
    "    out[\"ModelType\"] = label\n",
    "\n",
    "    return out\n",
    "\n",
    "frames = [read_and_label(p, label) for p, label in MODEL_LABELS.items()]\n",
    "combined = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "combined_out = os.path.join(OUT_DIR, \"combined_by_community_metrics.csv\")\n",
    "combined.to_csv(combined_out, index=False)\n",
    "print(f\"[saved combined metrics] {os.path.abspath(combined_out)}\")\n",
    "\n",
    "# load shapefile\n",
    "gdf_geo = gpd.read_file(COMMUNITY_SHP)\n",
    "if gdf_geo.crs is None or gdf_geo.crs.to_epsg() != 4326:\n",
    "    gdf_geo = gdf_geo.to_crs(epsg=4326)\n",
    "\n",
    "CAND_KEYS = [\"area_numbe\",\"area_num_1\",\"area_num\",\"AREA_NUMBE\",\"AREA_NUM_1\",\"AREA_NUM\"]\n",
    "geo_cols = list(gdf_geo.columns)\n",
    "left_key = next((k for k in CAND_KEYS if k in geo_cols), None)\n",
    "\n",
    "if left_key is None:\n",
    "    for col in gdf_geo.columns:\n",
    "        if col.lower().startswith(\"area\") and pd.api.types.is_numeric_dtype(gdf_geo[col]):\n",
    "            try:\n",
    "                if pd.to_numeric(gdf_geo[col], errors=\"coerce\").dropna().between(1, 77).all():\n",
    "                    left_key = col\n",
    "                    break\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "if left_key is None:\n",
    "    raise RuntimeError(f\"Couldn't find community_area ID column in shapefile. Columns: {geo_cols[:10]}\")\n",
    "\n",
    "gdf_geo[left_key] = pd.to_numeric(gdf_geo[left_key], errors=\"coerce\").astype(\"Int64\")\n",
    "geojson_obj = json.loads(gdf_geo.to_json())\n",
    "\n",
    "# color scaling\n",
    "def metric_scale(values):\n",
    "    vals = pd.Series(values).dropna()\n",
    "    if len(vals) == 0:\n",
    "        return 0.0, 1.0\n",
    "    vmin, vmax = float(vals.min()), float(vals.max())\n",
    "    if math.isclose(vmin, vmax):\n",
    "        vmin -= 1e-9\n",
    "        vmax += 1e-9\n",
    "    return vmin, vmax\n",
    "\n",
    "def _per_map_scale(df_model, metric):\n",
    "    dfm = df_model.copy()\n",
    "    if \"n_obs\" in dfm.columns:\n",
    "        dfm = dfm[pd.to_numeric(dfm[\"n_obs\"], errors=\"coerce\").fillna(0) >= MIN_SUPPORT]\n",
    "    series = pd.to_numeric(dfm[metric], errors=\"coerce\") if metric in dfm.columns else pd.Series([], dtype=float)\n",
    "    return metric_scale(series)\n",
    "\n",
    "def build_lookup(df, metric):\n",
    "    lookup = {}\n",
    "    has_n = \"n_obs\" in df.columns\n",
    "    for _, r in df.iterrows():\n",
    "        ca = r.get(\"community_area\", None)\n",
    "        if pd.isna(ca):\n",
    "            continue\n",
    "        entry = {\"metric\": None, \"n\": None}\n",
    "        if metric in df.columns and pd.notnull(r.get(metric, np.nan)):\n",
    "            entry[\"metric\"] = float(r[metric])\n",
    "        if has_n and pd.notnull(r.get(\"n_obs\", np.nan)):\n",
    "            entry[\"n\"] = int(r[\"n_obs\"])\n",
    "        lookup[int(ca)] = entry\n",
    "    return lookup\n",
    "\n",
    "def make_style_func(lookup, colormap):\n",
    "    def _style(feat):\n",
    "        ca_val = feat[\"properties\"].get(left_key)\n",
    "        try:\n",
    "            ca = int(ca_val)\n",
    "        except Exception:\n",
    "            ca = None\n",
    "\n",
    "        fill = \"#dddddd\"\n",
    "        opacity = 0.3\n",
    "        if ca in lookup:\n",
    "            val = lookup[ca][\"metric\"]\n",
    "            n   = lookup[ca][\"n\"]\n",
    "            if val is not None and (n is None or n >= MIN_SUPPORT):\n",
    "                fill = colormap(val)\n",
    "                opacity = 0.8\n",
    "\n",
    "        return {\"fillColor\": fill, \"color\": \"#202020\", \"weight\": 0.7, \"fillOpacity\": opacity}\n",
    "    return _style\n",
    "\n",
    "def _colormap(metric, vmin, vmax):\n",
    "    if metric == \"Arrest_Rate_true\":\n",
    "        return LinearColormap(\n",
    "            colors=[\"#ffffb2\", \"#fecc5c\", \"#fd8d3c\", \"#f03b20\", \"#bd0026\"],\n",
    "            vmin=vmin, vmax=vmax\n",
    "        )\n",
    "    else:\n",
    "        return LinearColormap([\"blue\", \"red\"], vmin=vmin, vmax=vmax)\n",
    "\n",
    "def make_map(geojson_obj, df_model, metric, title, filename):\n",
    "    if metric not in df_model.columns:\n",
    "        print(f\"[warn] Metric '{metric}' missing; skipping map '{title}'.\")\n",
    "        return None\n",
    "\n",
    "    vmin, vmax = _per_map_scale(df_model, metric)\n",
    "    cmap = _colormap(metric, vmin, vmax)\n",
    "    cmap.caption = title\n",
    "\n",
    "    lookup = build_lookup(df_model, metric)\n",
    "\n",
    "    m = folium.Map(location=[41.8781, -87.6298], zoom_start=10, tiles=\"cartodbpositron\")\n",
    "    folium.GeoJson(\n",
    "        data=geojson_obj,\n",
    "        name=title,\n",
    "        style_function=make_style_func(lookup, cmap),\n",
    "        tooltip=folium.features.GeoJsonTooltip(\n",
    "            fields=[left_key] + ([\"community\"] if \"community\" in gdf_geo.columns else []),\n",
    "            aliases=[\"Area #\"] + ([\"Community\"] if \"community\" in gdf_geo.columns else []),\n",
    "            localize=True,\n",
    "            sticky=False,\n",
    "            labels=True\n",
    "        ),\n",
    "        highlight_function=lambda x: {\"weight\": 2, \"color\": \"#000000\"},\n",
    "    ).add_to(m)\n",
    "\n",
    "    cmap.add_to(m)\n",
    "    folium.LayerControl(collapsed=True).add_to(m)\n",
    "\n",
    "    out_html = os.path.join(OUT_DIR, filename)\n",
    "    m.save(out_html)\n",
    "    print(f\"[saved map] {os.path.abspath(out_html)}\")\n",
    "    return out_html\n",
    "\n",
    "html_paths = []\n",
    "\n",
    "#model maps\n",
    "for model_name in sorted(combined[\"ModelType\"].unique()):\n",
    "    df_m = combined[combined[\"ModelType\"] == model_name]\n",
    "    for metric in PER_MODEL_METRICS:\n",
    "        p = make_map(\n",
    "            geojson_obj,\n",
    "            df_m,\n",
    "            metric,\n",
    "            title=f\"{metric} — {model_name}\",\n",
    "            filename=f\"{model_name}_{metric}.html\"\n",
    "        )\n",
    "        if p: html_paths.append(p)\n",
    "\n",
    "#arrest rate\n",
    "if SINGLE_METRIC in combined.columns:\n",
    "    ar_df = (combined[[\"community_area\", SINGLE_METRIC, \"n_obs\"]]\n",
    "             .dropna(subset=[\"community_area\", SINGLE_METRIC])\n",
    "             .sort_values([\"community_area\"])\n",
    "             .drop_duplicates(subset=[\"community_area\"]))\n",
    "    p = make_map(\n",
    "        geojson_obj,\n",
    "        ar_df,\n",
    "        SINGLE_METRIC,\n",
    "        title=\"Arrest Rate (Observed)\",\n",
    "        filename=\"Arrest_Rate_true.html\"\n",
    "    )\n",
    "    if p: html_paths.append(p)\n",
    "else:\n",
    "    print(\"[warn] No Arrest_Rate_true column found in any input; skipping that map.\")\n",
    "\n",
    "\n",
    "for p in html_paths:\n",
    "    try:\n",
    "        webbrowser.open(f\"file://{os.path.abspath(p)}\")\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18654c48-50b4-4c4c-8cf2-4c1f2daf11ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
